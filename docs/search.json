[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bowen Yao",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Project",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nBowen Yao\n\n\nApr 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, more than 50,000 previous donors were randomly assigned to receive one of several direct-mail solicitations. These solicitations varied in three main dimensions: - Whether a matching grant was offered, and at what ratio ($1:$1, $2:$1, or $3:$1), - The maximum threshold for matching (e.g., $25,000, $50,000, or $100,000), - The suggested donation amount on the reply card, based on prior giving history.\nThe central hypothesis was that offering a matching grant would increase both the likelihood of giving and the total donation amount. The authors also explored whether larger match ratios (e.g., $3:$1) would be more effective than smaller ones.\nImportantly, because of the randomized assignment of treatments, the experiment allows for clean causal inference on the effect of each fundraising strategy.\nOne notable finding from their analysis was that offering any match significantly increased donations, but increasing the match ratio beyond $1:$1 had no additional benefit. Moreover, they found that responses varied by political context—the treatment effects were stronger in U.S. states that voted for George W. Bush in the 2004 presidential election.\nThis project seeks to replicate and visualize these key findings using the original dataset and modern statistical tools."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, more than 50,000 previous donors were randomly assigned to receive one of several direct-mail solicitations. These solicitations varied in three main dimensions: - Whether a matching grant was offered, and at what ratio ($1:$1, $2:$1, or $3:$1), - The maximum threshold for matching (e.g., $25,000, $50,000, or $100,000), - The suggested donation amount on the reply card, based on prior giving history.\nThe central hypothesis was that offering a matching grant would increase both the likelihood of giving and the total donation amount. The authors also explored whether larger match ratios (e.g., $3:$1) would be more effective than smaller ones.\nImportantly, because of the randomized assignment of treatments, the experiment allows for clean causal inference on the effect of each fundraising strategy.\nOne notable finding from their analysis was that offering any match significantly increased donations, but increasing the match ratio beyond $1:$1 had no additional benefit. Moreover, they found that responses varied by political context—the treatment effects were stronger in U.S. states that voted for George W. Bush in the 2004 presidential election.\nThis project seeks to replicate and visualize these key findings using the original dataset and modern statistical tools."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\ndf.shape\n\n(50083, 51)\n\n\n\ndf.dtypes\n\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object\n\n\n\ndf.isnull().sum()\n\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n\n\nThe dataset contains 50,083 observations and 51 variables. Each row represents a unique individual who received one of the fundraising letters in the Karlan and List (2007) field experiment.\nThe variables include: - Treatment indicators (treatment, control, ratio, size, etc.) describing the type and details of the fundraising letter received. - Suggested donation values and historical giving behavior (ask, ask1, hpa, etc.). - Outcome variables, such as whether a donation was made (gave) and the amount given (amount). - Demographic and geographic variables, such as gender (female), income (median_hhincome), and urbanization (pop_propurban).\nMost variables are either integer-coded dummy variables or numeric, with some categorical fields (e.g., ratio, size, ask).\nThe dataset is overall very clean: - The vast majority of columns have no missing values. - A few variables, primarily those related to demographics (e.g., female, couple, pwhite, median_hhincome), contain some missing values—up to around 3.7% missing in the worst case (1,874 out of 50,083). - These missing values are mostly concentrated in the geographic/demographic features and do not affect the treatment or outcome variables.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy import stats\nfrom tabulate import tabulate\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\nvariables_to_test = ['mrm2', 'freq', 'female']\n\nresults = []\n\nfor var in variables_to_test:\n    subset = df[['treatment', var]].dropna()\n\n    treat = subset[subset['treatment'] == 1][var]\n    control = subset[subset['treatment'] == 0][var]\n\n    x1, x2 = treat.mean(), control.mean()\n    s1, s2 = treat.std(), control.std()\n    n1, n2 = treat.count(), control.count()\n    t_stat = (x1 - x2) / np.sqrt((s1**2)/n1 + (s2**2)/n2)\n    dfree = min(n1, n2) - 1\n    p_val_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), dfree))\n\n    model = smf.ols(f\"{var} ~ treatment\", data=subset).fit()\n    reg = model.summary2().tables[1].loc['treatment']\n\n    results.append([\n        var,\n        round(x1, 3), round(x2, 3),\n        round(t_stat, 3), round(p_val_ttest, 4),\n        round(reg['Coef.'], 3), round(reg['Std.Err.'], 3),\n        round(reg['t'], 3), round(reg['P&gt;|t|'], 4)\n    ])\n\nheaders = [\"Variable\", \"Mean (Treat)\", \"Mean (Control)\",\n           \"T-stat (manual)\", \"P-val (t-test)\",\n           \"Coef (reg)\", \"Std Err\", \"T-stat (reg)\", \"P-val (reg)\"]\n\nprint(tabulate(results, headers=headers, tablefmt=\"github\"))\n\n| Variable   |   Mean (Treat) |   Mean (Control) |   T-stat (manual) |   P-val (t-test) |   Coef (reg) |   Std Err |   T-stat (reg) |   P-val (reg) |\n|------------|----------------|------------------|-------------------|------------------|--------------|-----------|----------------|---------------|\n| mrm2       |         13.012 |           12.998 |             0.12  |           0.9049 |        0.014 |     0.115 |          0.119 |        0.9049 |\n| freq       |          8.035 |            8.047 |            -0.111 |           0.9117 |       -0.012 |     0.108 |         -0.111 |        0.9117 |\n| female     |          0.275 |            0.283 |            -1.754 |           0.0795 |       -0.008 |     0.004 |         -1.758 |        0.0787 |\n\n\nAs a robustness check on the validity of the randomization procedure, I performed balance tests comparing the treatment and control groups across three pre-treatment variables that are not outcome variables:\n\nmrm2 (months since last donation),\n\nfreq (number of prior donations),\n\nfemale (gender indicator).\n\nFor each variable, I performed both a manual t-test and a simple linear regression with the variable as the outcome and treatment as the predictor.\nWe can see that none of the variables exhibit statistically significant differences between the treatment and control groups at the 95% confidence level. All t-statistics are small in absolute value and p-values are above 0.05. The manual t-tests and regression results match perfectly, as expected\n\n\nInterpretation & Comparison with Table 1 in the Paper\nThese findings replicate what is shown in Table 1 of Karlan and List (2007), which also shows minimal differences between treatment and control groups across various pre-treatment characteristics. Table 1 is included in the original paper as a demonstration of successful randomization. If randomization is properly implemented, the only expected differences between groups should be due to chance — not systematic differences in characteristics.\nOur results confirm this. Variables such as months since last donation, number of prior donations, and gender are all statistically balanced across groups. This supports the internal validity of the experiment and allows us to interpret any differences in donation outcomes as causal effects of the treatment rather than artifacts of initial imbalance."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndonation_rate = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rate[\"Group\"] = donation_rate[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(6, 4))\n\ncolors = [\"#4C72B0\", \"#55A868\"] \nsns.barplot(x=\"Group\", y=\"gave\", data=donation_rate, palette=colors)\nplt.ylim(0, 0.03)\nplt.ylabel(\"Proportion Donated\", fontsize=12)\nplt.title(\"Donation Rate by Treatment Group\", fontsize=14)\nplt.xlabel(\"\")\nplt.xticks(fontsize=11)\nplt.yticks(fontsize=11)\nplt.tight_layout()\n\nplt.show()\n\nC:\\Users\\25645\\AppData\\Local\\Temp\\ipykernel_28864\\3870666356.py:13: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\nThe bar plot above illustrates the proportion of individuals who donated in each group. The treatment group, who received a matching offer, shows a slightly higher donation rate than the control group.\n\nimport numpy as np\nimport statsmodels.formula.api as smf\nfrom scipy import stats\ndf_gave = df[['treatment', 'gave']].dropna()\n\ntreat = df_gave[df_gave['treatment'] == 1]['gave']\ncontrol = df_gave[df_gave['treatment'] == 0]['gave']\n\nx1, x2 = treat.mean(), control.mean()\ns1, s2 = treat.std(), control.std()\nn1, n2 = treat.count(), control.count()\nt_stat = (x1 - x2) / np.sqrt((s1**2)/n1 + (s2**2)/n2)\ndfree = min(n1, n2) - 1\np_val_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), dfree))\n\nmodel = smf.ols(\"gave ~ treatment\", data=df_gave).fit()\nreg_result = model.summary2().tables[1].loc['treatment']\n\nprint(f\"Manual t-test: t = {t_stat:.3f}, p = {p_val_ttest:.4f}\")\nprint(f\"Regression: Coef = {reg_result['Coef.']:.4f}, Std Err = {reg_result['Std.Err.']:.4f}, t = {reg_result['t']:.3f}, p = {reg_result['P&gt;|t|']:.4f}\")\n\nManual t-test: t = 3.209, p = 0.0013\nRegression: Coef = 0.0042, Std Err = 0.0013, t = 3.101, p = 0.0019\n\n\nThe t-test and regression results show that the treatment group had a donation rate approximately 0.42 percentage points higher than the control group, which aligns closely with the difference reported in Table 2A Panel A of the original study (2.2% vs. 1.8%).\nOur t-statistic (~3.2) and p-value (0.0013) indicate that this difference is statistically significant at well below the 1% level. The regression confirms this with a nearly identical coefficient and standard error.\n\n\nInterpretation\nEven though the difference in donation rates might seem small numerically, it is statistically meaningful and practically important in the context of large-scale fundraising. The key insight is that human generosity is not fixed — it can be influenced by how giving opportunities are presented.\nThe presence of a matching grant doesn’t just increase the value of each donation; it also creates a psychological incentive. People may feel that their impact is greater when a match is involved, or that someone else is “joining them” in the cause. This social framing makes them more likely to act. This finding has broad implications for nonprofit fundraising and behavioral economics more generally: well-designed, low-cost incentives can powerfully nudge human behavior.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf_probit = df[['gave', 'treatment']].dropna()\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=df_probit).fit()\n\nmarginal_effects = probit_model.get_margeff()\nmarginal_table = marginal_effects.summary_frame()\noutput = marginal_table[['dy/dx', 'Std. Err.', 'z', 'Pr(&gt;|z|)']]\noutput.columns = ['Marginal Effect', 'Std. Error', 'z', 'p-value']\nfrom tabulate import tabulate\nprint(tabulate(output, headers='keys', tablefmt='github'))\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n|           |   Marginal Effect |   Std. Error |       z |    p-value |\n|-----------|-------------------|--------------|---------|------------|\n| treatment |        0.00431321 |   0.00138938 | 3.10442 | 0.00190653 |\n\n\nThis result confirms the finding in Table 3, Column 1 of Karlan and List (2007): assignment to the treatment group (i.e., receiving a matching donation offer) increases the probability of donating by approximately 0.4 percentage points, and the effect is statistically significant at the 1% level.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nimport pandas as pd\nimport scipy.stats as stats\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf_match = df[df['treatment'] == 1]\n\ngave_1to1 = df_match[(df_match['ratio2'] == 0) & (df_match['ratio3'] == 0)]['gave'].dropna()\ngave_2to1 = df_match[df_match['ratio2'] == 1]['gave'].dropna()\ngave_3to1 = df_match[df_match['ratio3'] == 1]['gave'].dropna()\n\ntstat_12, pval_12 = stats.ttest_ind(gave_1to1, gave_2to1)\ntstat_13, pval_13 = stats.ttest_ind(gave_1to1, gave_3to1)\ntstat_23, pval_23 = stats.ttest_ind(gave_2to1, gave_3to1)\n\nprint(\"1:1 vs 2:1 (within treatment) --&gt; t = {:.3f}, p = {:.4f}\".format(tstat_12, pval_12))\nprint(\"1:1 vs 3:1 (within treatment) --&gt; t = {:.3f}, p = {:.4f}\".format(tstat_13, pval_13))\nprint(\"2:1 vs 3:1 (within treatment) --&gt; t = {:.3f}, p = {:.4f}\".format(tstat_23, pval_23))\n\n1:1 vs 2:1 (within treatment) --&gt; t = -0.965, p = 0.3345\n1:1 vs 3:1 (within treatment) --&gt; t = -1.015, p = 0.3101\n2:1 vs 3:1 (within treatment) --&gt; t = -0.050, p = 0.9600\n\n\nTo test the claim made by the authors that “larger match ratios… have no additional impact” (page 8), I conducted a series of t-tests comparing donation rates between different match ratios. The output from the code support the authors’ observation that although donation rates vary slightly across match ratios, these differences are not statistically meaningful. The numbers alone may “suggest” a higher rate under 2:1 matches, but our analysis shows that this is likely due to random variation rather than a true treatment effect.\n\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.formula.api as smf\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_match = df[df['treatment'] == 1]\n\ndf_ratio1 = df_match[(df_match['ratio2'] == 0) & (df_match['ratio3'] == 0)]\ndf_ratio2 = df_match[df_match['ratio2'] == 1]\ndf_ratio3 = df_match[df_match['ratio3'] == 1]\n\nmodel1 = smf.ols('gave ~ 1', data=df_ratio1).fit()\nmodel2 = smf.ols('gave ~ 1', data=df_ratio2).fit()\nmodel3 = smf.ols('gave ~ 1', data=df_ratio3).fit()\n\nprint(\"Ratio 1:1 mean gave =\", model1.params.iloc[0])\nprint(\"Ratio 2:1 mean gave =\", model2.params.iloc[0])\nprint(\"Ratio 3:1 mean gave =\", model3.params.iloc[0])\n\nRatio 1:1 mean gave = 0.0207491242252762\nRatio 2:1 mean gave = 0.022633375246991206\nRatio 3:1 mean gave = 0.02273339922724415\n\n\nI estimated three separate regressions, each restricted to a different match ratio group within the treatment population. Each model estimates the average probability of donating (gave) under the respective match ratio.\n\nUnder a 1:1 match, the donation rate was approximately 2.07%\nUnder a 2:1 match, the rate was 2.26%\nUnder a 3:1 match, the rate was 2.27%\n\nAlthough there are small numerical differences, they are not statistically significant, as confirmed by the earlier t-tests. These findings support the authors’ conclusion that increasing the match ratio beyond 1:1 does not meaningfully increase the likelihood of giving.\n\nmean_ratio1 = model1.params.iloc[0]\nmean_ratio2 = model2.params.iloc[0]\nmean_ratio3 = model3.params.iloc[0]\ndiff_21 = mean_ratio2 - mean_ratio1\ndiff_32 = mean_ratio3 - mean_ratio2\n\nprint(\"\\nDifferences from regression-based fitted coefficients:\")\nprint(\"Difference (2:1 - 1:1) =\", diff_21)\nprint(\"Difference (3:1 - 2:1) =\", diff_32)\n\ndirect_mean1 = df_ratio1['gave'].mean()\ndirect_mean2 = df_ratio2['gave'].mean()\ndirect_mean3 = df_ratio3['gave'].mean()\n\nprint(\"\\nDirectly calculated group means:\")\nprint(\"Directly calculated mean (1:1) =\", direct_mean1)\nprint(\"Directly calculated mean (2:1) =\", direct_mean2)\nprint(\"Directly calculated mean (3:1) =\", direct_mean3)\ndirect_diff_21 = direct_mean2 - direct_mean1\ndirect_diff_32 = direct_mean3 - direct_mean2\n\nprint(\"\\nDifferences computed directly from the data:\")\nprint(\"Difference (2:1 - 1:1) =\", direct_diff_21)\nprint(\"Difference (3:1 - 2:1) =\", direct_diff_32)\n\n\nDifferences from regression-based fitted coefficients:\nDifference (2:1 - 1:1) = 0.0018842510217150048\nDifference (3:1 - 2:1) = 0.00010002398025294248\n\nDirectly calculated group means:\nDirectly calculated mean (1:1) = 0.020749124225276205\nDirectly calculated mean (2:1) = 0.0226333752469912\nDirectly calculated mean (3:1) = 0.022733399227244138\n\nDifferences computed directly from the data:\nDifference (2:1 - 1:1) = 0.0018842510217149944\nDifference (3:1 - 2:1) = 0.00010002398025293902\n\n\n\n\nEffectiveness of Different Match Ratios\nTo assess whether the size of the matched donation affects response rates, I calculated the donation rate differences between the three match ratios using two approaches: (1) fitted values from separate regressions, and (2) direct group means from the data.\n\nThe response rate difference between 2:1 and 1:1 was 0.00188 (about 0.19 percentage points).\nThe response rate difference between 3:1 and 2:1 was only 0.00010 (about 0.01 percentage points).\n\nThese values are nearly identical between the regression-based and data-based methods, confirming the robustness of the findings.\n\n\nConclusion:\nWhile the 2:1 match ratio shows a slightly higher response rate than 1:1, the difference is very small, and the additional increase from 2:1 to 3:1 is almost negligible. These findings support the conclusion from the original paper that increasing the match ratio beyond 1:1 does not meaningfully enhance the likelihood of donation.\nThe implication is that once the psychological effect of a matching grant is introduced, making the match more generous (e.g., 2:1 or 3:1) offers little additional motivational benefit. The presence of a match itself is impactful — but its size does not substantially change behavior.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_amt = df[['amount', 'treatment']].dropna()\ntreat_amt = df_amt[df_amt['treatment'] == 1]['amount']\nctrl_amt = df_amt[df_amt['treatment'] == 0]['amount']\n\nt_stat, p_val = stats.ttest_ind(treat_amt, ctrl_amt)\nprint(\"T-test: t = {:.3f}, p = {:.4f}\".format(t_stat, p_val))\n\nT-test: t = 1.861, p = 0.0628\n\n\nTo evaluate whether offering a matching donation affects the size of contributions (i.e., the donation amount), I conducted a t-test comparing the average donation between the treatment and control groups.\nThe t-test yielded: - t = 1.861 - p = 0.0628\n\n\nInterpretation\nThe result suggests that individuals in the treatment group — those who were offered a matching donation — gave more on average than those in the control group. However, this difference is not statistically significant at the conventional 5% level, though it is marginally significant at the 10% level.\nIt appears that the presence of a match may increase donation amounts, but the effect is not strong enough to be conclusive using this method alone. The modest significance may reflect the fact that most of the increase in total fundraising comes from a higher likelihood of giving, not necessarily from larger gifts among those who give.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_positive = df[df['amount'] &gt; 0][['amount', 'treatment']].dropna()\nmodel = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\nmodel.summary2().tables[1]\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nIntercept\n45.540268\n2.423378\n18.792063\n5.473578e-68\n40.784958\n50.295579\n\n\ntreatment\n-1.668393\n2.872384\n-0.580839\n5.614756e-01\n-7.304773\n3.967986\n\n\n\n\n\n\n\n\n\nInterpretation of Regression Coefficients\nThis regression analyzes how much people donate, conditional on having donated at all (amount &gt; 0). The outcome variable is the donation amount, and the independent variable is treatment (whether the donor received a matching donation offer).\n\nThe intercept (45.54) represents the average donation amount among control group donors (i.e., those who did not receive a matching offer).\nThe treatment coefficient (−1.67) tells us that, conditional on giving, donors in the treatment group gave $1.67 less on average than those in the control group.\nHowever, this difference is not statistically significant (p = 0.561), and the 95% confidence interval includes zero (from about −7.30 to +3.96). ### Does the Coefficient Have a Causal Interpretation? No, the treatment coefficient in this regression does not have a clean causal interpretation, because the sample is conditioned on the outcome (i.e., we only include people who gave). Since treatment status affects who chooses to give, the two groups may no longer be comparable. This introduces selection bias.\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_positive = df[df['amount'] &gt; 0]\n\ncontrol_donors = df_positive[df_positive['treatment'] == 0]\ntreat_donors = df_positive[df_positive['treatment'] == 1]\n\nmean_ctrl = control_donors['amount'].mean()\nmean_treat = treat_donors['amount'].mean()\n\nsns.set(style=\"whitegrid\")\nfig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\nsns.histplot(control_donors['amount'], bins=30, ax=axs[0], color=\"#4C72B0\")\naxs[0].axvline(mean_ctrl, color='red', linestyle='--', label=f'Mean: ${mean_ctrl:.2f}')\naxs[0].set_title(\"Control Group (Donors Only)\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].legend()\n\nsns.histplot(treat_donors['amount'], bins=30, ax=axs[1], color=\"#55A868\")\naxs[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')\naxs[1].set_title(\"Treatment Group (Donors Only)\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend()\n\nplt.suptitle(\"Histogram of Donation Amounts (Among Donors)\", fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(42)\n\nn_simulations = 10000\nn_per_group = 100\ndiffs = []\nfor _ in range(n_simulations):\n    treat_group = np.random.binomial(1, 0.022, size=n_per_group)\n    control_group = np.random.binomial(1, 0.018, size=n_per_group)\n    \n    treat_avg = np.mean(treat_group)\n    control_avg = np.mean(control_group)\n    \n    diffs.append(treat_avg - control_avg)\ndiffs = np.array(diffs)\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_simulations + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average Difference', color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label='True Difference = 0.004')\nplt.title(\"Law of Large Numbers: Cumulative Average of Treatment - Control\")\nplt.xlabel(\"Number of Simulated Pairs\")\nplt.ylabel(\"Average Difference\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation follows the logic of the Law of Large Numbers (LLN) by repeatedly simulating experiments with independent treatment and control groups. For each of 10,000 simulated experiments, we draw 100 observations from a control distribution (p = 0.018) and 100 from a treatment distribution (p = 0.022), calculate the difference in means, and plot the cumulative average of those differences.\nAs the number of experiments increases, the cumulative average stabilizes around the true population difference of 0.004, demonstrating that the average of estimates converges to the true value with enough data — exactly as predicted by the LLN.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nn_simulations = 1000\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    differences = []\n    for _ in range(n_simulations):\n        treat = np.random.binomial(1, p_treatment, size=n)\n        control = np.random.binomial(1, p_control, size=n)\n        diff = np.mean(treat) - np.mean(control)\n        differences.append(diff)\n    axs[i].hist(differences, bins=30, color='skyblue', edgecolor='black')\n    axs[i].axvline(0, color='red', linestyle='--', label='Zero')\n    axs[i].axvline(0.004, color='green', linestyle='--', label='True diff = 0.004')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Avg. Treatment - Control\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Sampling Distribution of Differences (CLT Simulation)\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n\n\n\n\n\n\n\n\nThese four histograms show the distribution of the average donation rate differences between treatment and control groups over 1,000 simulated experiments at sample sizes of 50, 200, 500, and 1000. In each experiment, we randomly drew observations from two Bernoulli distributions (p=0.022 for treatment and p=0.018 for control) and computed the average difference.\n\nSample Size = 50:\nThe distribution is very wide and highly variable. Zero lies well within the bulk of the distribution, meaning it’s not uncommon to observe sample differences near or even below zero due to noise. This reflects high sampling variability with small samples.\nSample Size = 200:\nThe distribution tightens and begins to center more clearly around the true difference of 0.004. Zero is still relatively close to the middle, but it’s less dominant compared to sample size 50.\nSample Size = 500:\nThe distribution is visibly more concentrated. The peak of the histogram is now clearly to the right of zero, closer to 0.004. Zero is moving toward the tail, indicating increasing power to detect the true effect.\nSample Size = 1000:\nAt this sample size, the distribution becomes even more narrow and sharply peaked around the true mean difference. Zero now lies clearly in the tail of the distribution. This means that if the true difference is 0.004, it is increasingly unlikely (with larger samples) to observe a result as small as zero just by chance."
  }
]